{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a483a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    ironical       0.70      0.63      0.66      4503\n",
      "     sincere       0.69      0.75      0.72      4893\n",
      "\n",
      "    accuracy                           0.69      9396\n",
      "   macro avg       0.69      0.69      0.69      9396\n",
      "weighted avg       0.69      0.69      0.69      9396\n",
      "\n",
      "Enter a Bengali comment to classify: আমাদের সম্প্রদায়ের জরুরী সমস্যাগুলি চিন্তামূলক বিবেচনা এবং নিশ্চিত পদক্ষেপের মাধ্যমে কঠোরভাবে অবগত করা উচিত|\n",
      "The comment is classified as: sincere\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "# Load datasets\n",
    "data = pd.read_csv(\"/Users/soubantiksengupta/Downloads/Bangla-Text-Dataset-main/dataset.csv\")\n",
    "factwatch_data = pd.read_csv(\"/Users/soubantiksengupta/Downloads/FactWatch-Data.csv\")\n",
    "toxlex_data = pd.read_csv(\"/Users/soubantiksengupta/Downloads/ToxLex_bn-output-v1-29-January-2022.csv\")\n",
    "\n",
    "# Define text cleaning and preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF]+', ' ', str(text))  # Keep Bengali chars\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Function to map labels for all datasets\n",
    "def map_labels(label, dataset='original'):\n",
    "    label = str(label)  # Ensure label is a string\n",
    "    if dataset == 'original':\n",
    "        return 'sincere' if label in ['sexual', 'not bully'] else 'ironical'\n",
    "    elif dataset == 'factwatch':\n",
    "        return 'sincere' if 'serious_condition' in label else 'ironical'\n",
    "    elif dataset == 'toxlex':\n",
    "        return 'sincere' if label == 'High' else 'ironical'\n",
    "\n",
    "# Preprocess and map labels\n",
    "data['processed_comment'] = data['comment'].apply(preprocess_text)\n",
    "data['mapped_label'] = data['label'].apply(map_labels)\n",
    "\n",
    "# Preprocessing new datasets\n",
    "factwatch_data['processed_content'] = factwatch_data['Post_Content_Summary'].apply(preprocess_text)\n",
    "factwatch_data['mapped_label'] = factwatch_data['Category'].apply(lambda x: map_labels(x, 'factwatch'))\n",
    "\n",
    "toxlex_data['processed_content'] = toxlex_data['Base_bigram'].apply(preprocess_text)\n",
    "toxlex_data['mapped_label'] = toxlex_data['Degree_of_toxicity'].apply(lambda x: map_labels(x, 'toxlex'))\n",
    "\n",
    "# Combine all datasets\n",
    "combined_data = pd.concat([\n",
    "    data[['processed_comment', 'mapped_label']],\n",
    "    factwatch_data[['processed_content', 'mapped_label']].rename(columns={'processed_content': 'processed_comment'}),\n",
    "    toxlex_data[['processed_content', 'mapped_label']].rename(columns={'processed_content': 'processed_comment'})\n",
    "])\n",
    "\n",
    "# Check for and remove any NaN values in 'mapped_label'\n",
    "combined_data = combined_data.dropna(subset=['mapped_label'])\n",
    "\n",
    "# Feature extraction and model training\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(combined_data['processed_comment'])\n",
    "y = combined_data['mapped_label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Function to classify new user input\n",
    "def classify_bengali_text(text):\n",
    "    processed_text = preprocess_text(text)\n",
    "    vectorized_text = tfidf_vectorizer.transform([processed_text])\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    return prediction[0]\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Example of classifying a new input\n",
    "user_input = input(\"Enter a Bengali comment to classify: \")\n",
    "classification_result = classify_bengali_text(user_input)\n",
    "print(f\"The comment is classified as: {classification_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc41e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 - General Social Media Comments:\n",
      "                                             comment    Category  Gender  \\\n",
      "0  ওই হালার পুত এখন কি মদ খাওয়ার সময় রাতের বেলা...       Actor  Female   \n",
      "1  ঘরে বসে শুট করতে কেমন লেগেছে? ক্যামেরাতে কে ছি...      Singer    Male   \n",
      "2                       অরে বাবা, এই টা কোন পাগল????       Actor  Female   \n",
      "3                              ক্যাপ্টেন অফ বাংলাদেশ      Sports    Male   \n",
      "4                                           পটকা মাছ  Politician    Male   \n",
      "\n",
      "   comment react number      label  \n",
      "0                   1.0     sexual  \n",
      "1                   2.0  not bully  \n",
      "2                   2.0  not bully  \n",
      "3                   0.0  not bully  \n",
      "4                   0.0      troll  \n",
      "\n",
      "Columns: Index(['comment', 'Category', 'Gender', 'comment react number', 'label'], dtype='object')\n",
      "\n",
      "Dataset 2 - FactWatch Data:\n",
      "   Post_ID                                         Post_Title  \\\n",
      "0      1.0  পঙ্গু হাসপাতালে কি কৃত্রিম পা সংযোজনের ক্যাম্প...   \n",
      "1      2.0  কুলাউড়ায় আসলেই কি হিন্দু আর মোসলমানের জন্য আলা...   \n",
      "2      3.0                             বানোয়াট: ছবি তোলার ছবি   \n",
      "3      4.0                 মায়ানমারে রোহিঙ্গা নির্যাতনের ছবি?   \n",
      "4      5.0      পাকিস্তান মিলিটারি জওয়ান কি খৎনা যাচাই করছিল?   \n",
      "\n",
      "                                Post_Content_Summary  \\\n",
      "0  জাতীয় অর্থোপেডিক হাসপাতাল ও পুনর্বাসন প্রতিষ্ঠ...   \n",
      "1  এই ছবিটি সোশ্যাল মিডিয়ায় ঘুরছে, সংখ্যালঘুদের ব...   \n",
      "2  এই ছবিটার অন্তত ৩ টা ভার্সন অনলাইনে ছড়ানো আছে।...   \n",
      "3  সোশ্যাল মিডিয়ায় অনেকেই দাবি করলেও এটি মায়ানমার...   \n",
      "4  এই ছবিতে পাকিস্তান আর্মির এক জওয়ান খৎনা পরীক্ষ...   \n",
      "\n",
      "                               Original_Content_Text Post_Rating  \\\n",
      "0   যদি কারো পরিচিত এমন কেউ থাকে যার হাটুর উপরে অ...         NaN   \n",
      "1                                 জ্বালাময়ী ব্যাখ্যা         NaN   \n",
      "2                                                NaN         NaN   \n",
      "3  রহিংগা যুবকদের দরে এনে জবাই করে জংগলে ফেলে দিচ...         NaN   \n",
      "4  বাংলাদেশ মুসলমানের দেশ??? কথাটা হর হামেশা শুনত...         NaN   \n",
      "\n",
      "                           Investigation_Description    Category  \n",
      "0  সাম্প্রতিক ভাইরাল গুজবের প্রেক্ষিতে ৩রা অক্টোব...   স্বাস্থ্য  \n",
      "1  আপাতদৃষ্টিতে সিলেটে কুলাউড়া রেলওয়ে স্টেশনের দু...  তথ্য যাচাই  \n",
      "2  এর আগে, ২০০৬ সালের ২০ নভেম্বরের এক ব্লগ পোস্টে...   ছবি যাচাই  \n",
      "3  ছবিটা আসলে ২০১৪ সালের, ‘রেডিওএলটি১২ (RadioLT12...   ছবি যাচাই  \n",
      "4  ফেসবুকে এই ছবিটা সবশেষ নজরে আসে ১৯ জানুয়ারি ২০...   ছবি যাচাই  \n",
      "\n",
      "Columns: Index(['Post_ID', 'Post_Title', 'Post_Content_Summary',\n",
      "       'Original_Content_Text', 'Post_Rating', 'Investigation_Description',\n",
      "       'Category'],\n",
      "      dtype='object')\n",
      "\n",
      "Dataset 3 - ToxLex Data:\n",
      "   ID     Base_bigram Meaning_(Approx.)      Transcription_(IPA)  \\\n",
      "0   1   অক্ষম পুরুষের      Impotent men         əkʂəmə puɾuʂeːɾə   \n",
      "1   2      অডিও সেক্স         Audio sex           əɖɪoː s̪eːks̪ə   \n",
      "2   3   অনৈসলামিক কাজ  Non-Islamic work  ən̪əɪs̪əlɑːmɪkə kɑːd͡ʒə   \n",
      "3   4  অন্ডকোষ কাটলেই  Cutting scrotum      ən̪ɖəkoːʂə kɑːʈəleːɪ   \n",
      "4   5     অন্ডকোষ হীন       Scrotumless        ən̪ɖəkoːʂə ɦiːn̪ə   \n",
      "\n",
      "               Themetic_category  Token_Occerance Unusual_ Spelling   \\\n",
      "0     Sexist & Patriarchic bully               38                 No   \n",
      "1     Sexist & Patriarchic bully               45                 No   \n",
      "2  Religion/ communal hate-words               13                 No   \n",
      "3     Sexist & Patriarchic bully                7                 No   \n",
      "4     Sexist & Patriarchic bully                6                 No   \n",
      "\n",
      "  Degree_of_toxicity  \n",
      "0                Mid  \n",
      "1                Mid  \n",
      "2                Mid  \n",
      "3                Mid  \n",
      "4                Mid  \n",
      "\n",
      "Columns: Index(['ID', 'Base_bigram', 'Meaning_(Approx.)', 'Transcription_(IPA)',\n",
      "       'Themetic_category', 'Token_Occerance', 'Unusual_ Spelling ',\n",
      "       'Degree_of_toxicity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "data = pd.read_csv(\"/Users/soubantiksengupta/Downloads/Bangla-Text-Dataset-main/dataset.csv\")\n",
    "factwatch_data = pd.read_csv(\"/Users/soubantiksengupta/Downloads/FactWatch-Data.csv\")\n",
    "toxlex_data = pd.read_csv(\"/Users/soubantiksengupta/Downloads/ToxLex_bn-output-v1-29-January-2022.csv\")\n",
    "\n",
    "# Print the first few rows of each dataset to understand their structure\n",
    "print(\"Dataset 1 - General Social Media Comments:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumns:\", data.columns)\n",
    "\n",
    "print(\"\\nDataset 2 - FactWatch Data:\")\n",
    "print(factwatch_data.head())\n",
    "print(\"\\nColumns:\", factwatch_data.columns)\n",
    "\n",
    "print(\"\\nDataset 3 - ToxLex Data:\")\n",
    "print(toxlex_data.head())\n",
    "print(\"\\nColumns:\", toxlex_data.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
